{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic regression with ARIMA errors.\n",
    "\n",
    "This notebook contains an implemenation of regression with ARIMA errors.\n",
    "\n",
    "In this implementation months of the year and weeks of the year are represented by seasonal indexes (dummy variables either 0 or 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from forecast_tools.baseline import SNaive, Naive1\n",
    "from forecast_tools.metrics import mean_absolute_error\n",
    "from forecast_tools.datasets import load_emergency_dept\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_as_series(data, preds):\n",
    "    '''\n",
    "    Helper function for plotting predictions.\n",
    "    Converts a numpy array of predictions to a \n",
    "    pandas.DataFrame with datetimeindex\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    data - arraylike - the training data\n",
    "    preds - numpy.array, vector of predictions \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "    '''\n",
    "    start = pd.date_range(start=data.index.max(), periods=2, \n",
    "                          freq=data.index.freq).max()\n",
    "    idx = pd.date_range(start=start, periods=len(preds), freq=data.index.freq)\n",
    "    return pd.DataFrame(preds, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_intervals(train, preds, intervals, \n",
    "                              test=None, show_train_size=None, figsize=(12,4)):\n",
    "    '''\n",
    "    Helper function to plot training data, point preds\n",
    "    and 2 sets of prediction intevals\n",
    "    \n",
    "    assume 2 sets of PIs are provided!\n",
    "    '''\n",
    "    \n",
    "    if show_train_size is None:\n",
    "        show_train_size = len(train)\n",
    "        \n",
    "    train = train[-show_train_size:]\n",
    "    ax = train.plot(figsize=figsize)\n",
    "    \n",
    "\n",
    "    mean = preds_as_series(train, preds)\n",
    "    intervals_80 = preds_as_series(train, intervals[0])\n",
    "    intervals_90 = preds_as_series(train, intervals[1])\n",
    "\n",
    "    mean.plot(ax=ax, label='point forecast')\n",
    "\n",
    "    ax.fill_between(intervals_80.index, mean[0], intervals_80[1], \n",
    "                    alpha=0.2,\n",
    "                    label='80% PI', color='yellow');\n",
    "\n",
    "    ax.fill_between(intervals_80.index,mean[0], intervals_80[0], \n",
    "                    alpha=0.2,\n",
    "                    label='80% PI', color='yellow');\n",
    "\n",
    "    ax.fill_between(intervals_80.index,intervals_80[1], intervals_90[1], \n",
    "                    alpha=0.2,\n",
    "                    label='90% PI', color='purple');\n",
    "\n",
    "    ax.fill_between(intervals_80.index,intervals_80[0], intervals_90[0], \n",
    "                    alpha=0.2,\n",
    "                    label='90% PI', color='purple');\n",
    "    \n",
    "    if test is None:\n",
    "        ax.legend(['train', 'point forecast', '80%PI', '_ignore','_ignore', \n",
    "                   '90%PI'], loc=2)\n",
    "    else:\n",
    "        test.plot(ax=ax, color='black', marker='o', ls='')\n",
    "        ax.legend(['train', 'point forecast', 'Test', '80%PI', \n",
    "                   '_ignore','_ignore', '90%PI'], loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to get seasonal indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasonal_indexes(idx, include_month=True, include_dow=True):\n",
    "    '''\n",
    "    Seasonal indexes for use with regression.\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    idx: pd.DataTimeIndex\n",
    "        Dates inclued in the dataframe\n",
    "        \n",
    "    include_month: bool, optional (default=True)\n",
    "        Include 11 dummy variables for month of year\n",
    "        \n",
    "    include_dow: bool. optional (default=False)\n",
    "        Include 6 dummy variables for month of year\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    seasonal_idx = pd.DataFrame()\n",
    "    \n",
    "    if include_month:\n",
    "        # uses the pd.get_dummies function \n",
    "        seasonal_idx = pd.concat([seasonal_idx, pd.get_dummies(idx.month,  prefix='m', \n",
    "                                                               drop_first=True)], axis=1)\n",
    "        \n",
    "    if include_dow:\n",
    "        seasonal_idx = pd.concat([seasonal_idx, pd.get_dummies(idx.weekday, prefix='dow', \n",
    "                                                               drop_first=True)], axis=1)\n",
    "        \n",
    "    # set the index\n",
    "    seasonal_idx.index = idx\n",
    "        \n",
    "    return seasonal_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with `forecast_tools` ED dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 0.80\n",
    "HOLDOUT = 28\n",
    "PERIOD = 7\n",
    "\n",
    "attends = load_emergency_dept()\n",
    "\n",
    "# train-test split\n",
    "train = attends[:-HOLDOUT]\n",
    "test = attends[-HOLDOUT:]\n",
    "\n",
    "\n",
    "X = get_seasonal_indexes(train.index)\n",
    "# quick look at \n",
    "X.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_arima(train, exogenous=X, m=PERIOD, d=1, supress_warnings=True, maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_future_dataframe(h, y_train, include_mth=True, include_dow=True):\n",
    "    '''\n",
    "    Make a dataframe h steps into the future of y_train\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    h: int\n",
    "        Forecast horizon\n",
    "        \n",
    "    y_train: pd.DataFrame\n",
    "        Dataframe containing training data.  Must have a DataTimeIndex\n",
    "    \n",
    "    '''\n",
    "    idx = pd.date_range(start=y_train.iloc[-1].name, periods=y_train.shape[0]+h, freq='D')\n",
    "    seasonal_idxs = get_seasonal_indexes(idx, include_month=True, include_dow=True)\n",
    "    return seasonal_idxs.iloc[-h:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dataframe = make_future_dataframe(HOLDOUT, train)\n",
    "future_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, future_dataframe, return_predict_int=True, alpha=0.05):\n",
    "    '''\n",
    "    Forecast with regression with ARIMA errors\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    h: int\n",
    "        Forecast horizon\n",
    "        \n",
    "    future_dataframe: pd.DataFrame\n",
    "        Future dataframe containing datetimeindex + seasonal indexes\n",
    "    \n",
    "    return_predict_int: bool, optional (default=True)\n",
    "        Prediction interval with predictions\n",
    "        \n",
    "    alpha: float, optional (Deault=0.05)\n",
    "        1 - coverage for prediction interval\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    preds, intervals\n",
    "    '''\n",
    "    \n",
    "    h = future_dataframe.shape[0]\n",
    "    return model.predict(n_periods=h, exogenous=future_dataframe, \n",
    "                         return_conf_int=return_predict_int, \n",
    "                         alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, intervals_95 = forecast(model, future_dataframe, alpha=0.05)\n",
    "preds, intervals_80 = forecast(model, future_dataframe, alpha=0.2)\n",
    "intervals = np.array([intervals_80, intervals_95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_intervals(train, preds, intervals, test=test, \n",
    "                          show_train_size=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n",
      "{'model': Average(), 'mae': 22.64866385564089}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from forecast_tools.model_selection import auto_naive\n",
    "\n",
    "# the reattends data we used in class.\n",
    "URL = \"https://raw.githubusercontent.com/health-data-science-OR/hpdm097-datasets\" \\\n",
    "    + \"/master/ed_reattends_day.csv\"\n",
    "\n",
    "# PARAMETERS for analysis.\n",
    "TRAIN_SIZE = len(reattends) // 3\n",
    "HORIZON = 28\n",
    "# seasonal period for auto_naive\n",
    "PERIOD = 365\n",
    "# step size for auto_naive (how many data points to add between splits.)\n",
    "STEP = 7\n",
    "\n",
    "# read data\n",
    "reattends = pd.read_csv(URL, parse_dates=True, dayfirst=True, index_col='date')\n",
    "reattends.index.freq = 'D'\n",
    "\n",
    "# temporal train-test sploot\n",
    "train, test = reattends[:TRAIN_SIZE], reattends[TRAIN_SIZE:]\n",
    "\n",
    "# This is how big my training data set is (with default settings should be 516)\n",
    "print(len(train))\n",
    "\n",
    "# auto naive makes multiple train test splits with the training data.\n",
    "# so we need the min training size to be > 365 \n",
    "\n",
    "# just using rolling forecast origin\n",
    "# I think the bug is with the method parameter.  if you set it to 'ro' it works.\n",
    "results = auto_naive(train, horizon=HORIZON, step=STEP, seasonal_period=PERIOD, \n",
    "                   method='ro', metric='mae', min_train_size=365)\n",
    "\n",
    "# mine selected average with a mae of around 22.6\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
